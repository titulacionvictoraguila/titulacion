{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pylibjpeg-libjpeg\n",
        "!pip install pylibjpeg\n",
        "!pip install pydicom\n",
        "!pip install keras-cv-attention-models\n",
        "!pip install dicomsdl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70LMtLPsYaKl",
        "outputId": "c003810c-e4cc-4aac-fb62-9c3cf3c695a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pylibjpeg-libjpeg\n",
            "  Downloading pylibjpeg_libjpeg-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from pylibjpeg-libjpeg) (1.22.4)\n",
            "Installing collected packages: pylibjpeg-libjpeg\n",
            "Successfully installed pylibjpeg-libjpeg-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "flWaQEJ4XsQv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directory paths\n",
        "cancer_dir = \"train/cancer\"\n",
        "no_cancer_dir = \"train/noCancer\"\n",
        "\n",
        "# Image dimensions\n",
        "img_width, img_height = 256, 256\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = pydicom.dcmread(os.path.join(folder, filename)).pixel_array\n",
        "        img = cv2.resize(img, (img_width, img_height))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "KDXxlJbfXwu0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images\n",
        "cancer_images, cancer_labels = load_images_from_folder(cancer_dir, 1)\n",
        "no_cancer_images, no_cancer_labels = load_images_from_folder(no_cancer_dir, 0)"
      ],
      "metadata": {
        "id": "hB2c-7nmX2oN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine and normalize images\n",
        "images = np.array(cancer_images + no_cancer_images) / 255.0\n",
        "labels = np.array(cancer_labels + no_cancer_labels)"
      ],
      "metadata": {
        "id": "2qiplktyX2jE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape data to fit model\n",
        "X_train = X_train.reshape(-1, img_width, img_height, 1)\n",
        "X_test = X_test.reshape(-1, img_width, img_height, 1)"
      ],
      "metadata": {
        "id": "RX_gC4-OXz2i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "def build_cnn(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Define model parameters\n",
        "input_shape = (img_width, img_height, 1)\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "oZjwIFzJX69r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile model\n",
        "model = build_cnn(input_shape, num_classes)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "LLYAhrisYnkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the modelo\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "4WEgcU1Diikq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy train & valid\n",
        "plt.figure(figsize=[6,4])\n",
        "plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
        "plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.ylabel('Accuracy', fontsize=10)\n",
        "plt.title('Accuracy Curves', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I6oyD9tFxNt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss train & valid\n",
        "plt.figure(figsize=[6,4])\n",
        "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
        "plt.plot(history.history['val_loss'], 'blue', linewidth=2.0)\n",
        "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=10)\n",
        "plt.title('Loss Curves', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PkJGgksfxTKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg9qikfixS-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}